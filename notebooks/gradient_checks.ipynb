{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple ipython notebook that does a few gradient checks for common operators. There is nothing much useful here - unless you would like to do some debugging. Due to the fact that the gradient checker is written in Python, there are a lot of communications going on so the whole check runs relatively slowly. Run at your own risk, and in the meantime, go grab a coffee. If everything is right, this should output all Trues. If some gradient is wrong, the script will print out the estimated and the computed gradients for your inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded nvd3 IPython extension\n",
      "run nvd3.IPython_wrapper.initialize_javascript() to set up the notebook\n",
      "help(nvd3.IPython_wrapper.initialize_javascript) for options\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from pycaffe2 import core, device_checker, gradient_checker, workspace\n",
    "from caffe2.proto import caffe2_pb2, caffe2_legacy_pb2\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import sys\n",
    "\n",
    "device_option = caffe2_pb2.DeviceOption()\n",
    "device_option.device_type = caffe2_pb2.CUDA\n",
    "\n",
    "cpu_device_option = caffe2_pb2.DeviceOption()\n",
    "device_checker = device_checker.DeviceChecker(0.01, [device_option, cpu_device_option])\n",
    "gpu_g_checker = gradient_checker.GradientChecker(0.005, 0.05, device_option, \"gpu_checker_ws\")\n",
    "cpu_g_checker = gradient_checker.GradientChecker(0.01, 0.05, cpu_device_option, \"cpu_checker_ws\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device test for 1 1 1 7 NHWC is:  True\n",
      "Test for cpu 1 1 1 7 NHWC is:  True\n",
      "Test for gpu 1 1 1 7 NHWC is:  True\n",
      "Device test for 1 1 2 7 NHWC is:  True\n",
      "Test for cpu 1 1 2 7 NHWC is:  True\n",
      "Test for gpu 1 1 2 7 NHWC is:  True\n",
      "Device test for 1 3 1 7 NHWC is:  True\n",
      "Test for cpu 1 3 1 7 NHWC is:  True\n",
      "Test for gpu 1 3 1 7 NHWC is:  True\n",
      "Device test for 1 3 2 7 NHWC is:  True\n",
      "Test for cpu 1 3 2 7 NHWC is:  True\n",
      "Test for gpu 1 3 2 7 NHWC is:  True\n",
      "Device test for 1 5 1 14 NHWC is:  True\n",
      "Test for cpu 1 5 1 14 NHWC is:  True\n",
      "Test for gpu 1 5 1 14 NHWC is:  True\n",
      "Device test for 1 5 2 14 NHWC is:  True\n",
      "Test for cpu 1 5 2 14 NHWC is:  True\n",
      "Test for gpu 1 5 2 14 NHWC is:  True\n",
      "Device test for 2 7 1 24 NHWC is:  True\n",
      "Test for cpu 2 7 1 24 NHWC is:  True\n",
      "Test for gpu 2 7 1 24 NHWC is:  True\n",
      "Device test for 2 7 2 24 NHWC is:  True\n",
      "Test for cpu 2 7 2 24 NHWC is:  True\n",
      "Test for gpu 2 7 2 24 NHWC is:  True\n",
      "Device test for 1 1 1 7 NCHW is:  True\n",
      "Test for cpu 1 1 1 7 NCHW is:  True\n",
      "Test for gpu 1 1 1 7 NCHW is:  True\n",
      "Device test for 1 1 2 7 NCHW is:  True\n",
      "Test for cpu 1 1 2 7 NCHW is:  True\n",
      "Test for gpu 1 1 2 7 NCHW is:  True\n",
      "Device test for 1 3 1 7 NCHW is:  True\n",
      "Test for cpu 1 3 1 7 NCHW is:  True\n",
      "Test for gpu 1 3 1 7 NCHW is:  True\n",
      "Device test for 1 3 2 7 NCHW is:  True\n",
      "Test for cpu 1 3 2 7 NCHW is:  True\n",
      "Test for gpu 1 3 2 7 NCHW is:  True\n",
      "Device test for 1 5 1 14 NCHW is:  True\n",
      "Test for cpu 1 5 1 14 NCHW is:  True\n",
      "Test for gpu 1 5 1 14 NCHW is:  True\n",
      "Device test for 1 5 2 14 NCHW is:  True\n",
      "Test for cpu 1 5 2 14 NCHW is:  True\n",
      "Test for gpu 1 5 2 14 NCHW is:  True\n",
      "Device test for 2 7 1 24 NCHW is:  True\n",
      "Test for cpu 2 7 1 24 NCHW is:  True\n",
      "Test for gpu 2 7 1 24 NCHW is:  True\n",
      "Device test for 2 7 2 24 NCHW is:  True\n",
      "Test for cpu 2 7 2 24 NCHW is:  True\n",
      "Test for gpu 2 7 2 24 NCHW is:  True\n"
     ]
    }
   ],
   "source": [
    "# This is for convolution layers with NHWC order.\n",
    "test_configs = [\n",
    "(1, 1, 1, 7, \"NHWC\"),\n",
    "(1, 1, 2, 7, \"NHWC\"),\n",
    "(1, 3, 1, 7, \"NHWC\"),\n",
    "(1, 3, 2, 7, \"NHWC\"),\n",
    "(1, 5, 1, 14, \"NHWC\"),\n",
    "(1, 5, 2, 14, \"NHWC\"),\n",
    "(2, 7, 1, 24, \"NHWC\"),\n",
    "(2, 7, 2, 24, \"NHWC\"),\n",
    "(1, 1, 1, 7, \"NCHW\"),\n",
    "(1, 1, 2, 7, \"NCHW\"),\n",
    "(1, 3, 1, 7, \"NCHW\"),\n",
    "(1, 3, 2, 7, \"NCHW\"),\n",
    "(1, 5, 1, 14, \"NCHW\"),\n",
    "(1, 5, 2, 14, \"NCHW\"),\n",
    "(2, 7, 1, 24, \"NCHW\"),\n",
    "(2, 7, 2, 24, \"NCHW\"),\n",
    "]\n",
    "\n",
    "for stride, kernel, legacy_pad, size, order in test_configs:\n",
    "    op = core.CreateOperator(\"Conv\")(\n",
    "        [\"X\", \"w\", \"b\"], [\"Y\"], stride=stride, kernel=kernel,\n",
    "        legacy_pad=legacy_pad, order=order, device_option=device_option)\n",
    "    if order == \"NHWC\":\n",
    "        X = np.random.rand(2, size, size, 3).astype(np.float32) - 0.5\n",
    "        w = np.random.rand(4, kernel, kernel, 3).astype(np.float32) - 0.5\n",
    "    else:\n",
    "        X = np.random.rand(2, 3, size, size).astype(np.float32) - 0.5\n",
    "        w = np.random.rand(4, 3, kernel, kernel).astype(np.float32) - 0.5        \n",
    "    b = np.random.rand(4).astype(np.float32) - 0.5\n",
    "    res = device_checker.CheckSimple(op, [X, w, b], [0])\n",
    "    print 'Device test for', stride, kernel, legacy_pad, size, order, 'is: ', res\n",
    "    res, grad, grad_estimated = cpu_g_checker.CheckSimple(op, [X, w, b], 0, [0])\n",
    "    print 'Test for cpu', stride, kernel, legacy_pad, size, order, 'is: ', res\n",
    "    if not res:\n",
    "        pyplot.figure()\n",
    "        pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "    sys.stdout.flush()\n",
    "    res, grad, grad_estimated = gpu_g_checker.CheckSimple(op, [X, w, b], 0, [0])\n",
    "    print 'Test for gpu', stride, kernel, legacy_pad, size, order, 'is: ', res\n",
    "    if not res:\n",
    "        pyplot.figure()\n",
    "        pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device test for 2 3 2 12 NHWC is:  True\n",
      "Test for cpu 2 3 2 12 NHWC is:  True\n",
      "Test for gpu 2 3 2 12 NHWC is:  True\n",
      "Device test for 2 3 2 16 NHWC is:  True\n",
      "Test for cpu 2 3 2 16 NHWC is:  True\n",
      "Test for gpu 2 3 2 16 NHWC is:  True\n",
      "Device test for 1 3 2 8 NHWC is:  True\n",
      "Test for cpu 1 3 2 8 NHWC is:  True\n",
      "Test for gpu 1 3 2 8 NHWC is:  True\n",
      "Device test for 1 3 2 14 NHWC is:  True\n",
      "Test for cpu 1 3 2 14 NHWC is:  True\n",
      "Test for gpu 1 3 2 14 NHWC is:  True\n",
      "Device test for 2 3 2 14 NHWC is:  True\n",
      "Test for cpu 2 3 2 14 NHWC is:  True\n",
      "Test for gpu 2 3 2 14 NHWC is:  True\n",
      "Device test for 1 3 2 7 NHWC is:  True\n",
      "Test for cpu 1 3 2 7 NHWC is:  True\n",
      "Test for gpu 1 3 2 7 NHWC is:  True\n",
      "Device test for 2 3 2 12 NCHW is:  True\n",
      "Test for cpu 2 3 2 12 NCHW is:  True\n",
      "Test for gpu 2 3 2 12 NCHW is:  True\n",
      "Device test for 2 3 2 16 NCHW is:  True\n",
      "Test for cpu 2 3 2 16 NCHW is:  True\n",
      "Test for gpu 2 3 2 16 NCHW is:  True\n",
      "Device test for 1 3 2 8 NCHW is:  True\n",
      "Test for cpu 1 3 2 8 NCHW is:  True\n",
      "Test for gpu 1 3 2 8 NCHW is:  True\n",
      "Device test for 1 3 2 14 NCHW is:  True\n",
      "Test for cpu 1 3 2 14 NCHW is:  True\n",
      "Test for gpu 1 3 2 14 NCHW is:  True\n",
      "Device test for 2 3 2 14 NCHW is:  True\n",
      "Test for cpu 2 3 2 14 NCHW is:  True\n",
      "Test for gpu 2 3 2 14 NCHW is:  True\n",
      "Device test for 1 3 2 7 NCHW is:  True\n",
      "Test for cpu 1 3 2 7 NCHW is:  True\n",
      "Test for gpu 1 3 2 7 NCHW is:  True\n"
     ]
    }
   ],
   "source": [
    "# This is for max pooling layers.\n",
    "test_configs = [\n",
    "(2, 3, 2, 12, \"NHWC\"),\n",
    "(2, 3, 2, 16, \"NHWC\"),\n",
    "(1, 3, 2, 8, \"NHWC\"),\n",
    "(1, 3, 2, 14, \"NHWC\"),\n",
    "(2, 3, 2, 14, \"NHWC\"),\n",
    "(1, 3, 2, 7, \"NHWC\"),\n",
    "(2, 3, 2, 12, \"NCHW\"),\n",
    "(2, 3, 2, 16, \"NCHW\"),\n",
    "(1, 3, 2, 8, \"NCHW\"),\n",
    "(1, 3, 2, 14, \"NCHW\"),\n",
    "(2, 3, 2, 14, \"NCHW\"),\n",
    "(1, 3, 2, 7, \"NCHW\"),\n",
    "]\n",
    "\n",
    "for stride, kernel, legacy_pad, size, order in test_configs:\n",
    "    op = core.CreateOperator(\"MaxPool\")(\n",
    "        [\"X\"], [\"Y\", \"Y_maxid\"], stride=stride, kernel=kernel,\n",
    "        legacy_pad=legacy_pad, order=order)\n",
    "    # In order to avoid the problem of race conditions, we will do a randperm\n",
    "    # so that the values will be apart at least \n",
    "    if order == \"NHWC\":\n",
    "        X = np.random.permutation(1 * size * size * 3).reshape(1, size, size, 3).astype(np.float32) * 0.01\n",
    "    else:\n",
    "        X = np.random.permutation(1 * size * size * 3).reshape(1, 3, size, size).astype(np.float32) * 0.01\n",
    "    res = device_checker.CheckSimple(op, [X], [0])\n",
    "    print 'Device test for', stride, kernel, legacy_pad, size, order, 'is: ', res\n",
    "    res, grad, grad_estimated = cpu_g_checker.CheckSimple(op, [X], 0, [0])\n",
    "    print 'Test for cpu', stride, kernel, legacy_pad, size, order, 'is: ', res\n",
    "    if not res:\n",
    "        pyplot.figure()\n",
    "        pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "    sys.stdout.flush()\n",
    "    res, grad, grad_estimated = gpu_g_checker.CheckSimple(op, [X], 0, [0])\n",
    "    print 'Test for gpu', stride, kernel, legacy_pad, size, order, 'is: ', res\n",
    "    if not res:\n",
    "        pyplot.figure()\n",
    "        pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device test for 1 7 1 7 is:  True\n",
      "Test for cpu 1 7 1 7 is:  True\n",
      "Test for gpu 1 7 1 7 is:  True\n",
      "Device test for 1 7 2 7 is:  True\n",
      "Test for cpu 1 7 2 7 is:  True\n",
      "Test for gpu 1 7 2 7 is:  True\n"
     ]
    }
   ],
   "source": [
    "# This is for average pooling layers.\n",
    "checker = gradient_checker.GradientChecker(0.01, 0.05, \"default\")\n",
    "test_configs = [\n",
    "(1, 7, 1, 7),\n",
    "(1, 7, 2, 7),\n",
    "]\n",
    "\n",
    "for stride, kernel, legacy_pad, size in test_configs:\n",
    "    op = core.CreateOperator(\"AveragePool\")(\n",
    "        [\"X\"], [\"Y\"], stride=stride, kernel=kernel,\n",
    "        legacy_pad=legacy_pad, order=\"NHWC\")\n",
    "    X = np.random.rand(2, size, size, 3).astype(np.float32)\n",
    "    res = device_checker.CheckSimple(op, [X], [0])\n",
    "    print 'Device test for', stride, kernel, legacy_pad, size, 'is: ', res\n",
    "    res, grad, grad_estimated = cpu_g_checker.CheckSimple(op, [X], 0, [0])\n",
    "    print 'Test for cpu', stride, kernel, legacy_pad, size, 'is: ', res\n",
    "    if not res:\n",
    "        pyplot.figure()\n",
    "        pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "    sys.stdout.flush()\n",
    "    res, grad, grad_estimated = gpu_g_checker.CheckSimple(op, [X], 0, [0])\n",
    "    print 'Test for gpu', stride, kernel, legacy_pad, size, 'is: ', res\n",
    "    if not res:\n",
    "        pyplot.figure()\n",
    "        pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is for lrn layers.\n",
    "test_configs = [\n",
    "(6, 10),\n",
    "(3, 13),\n",
    "]\n",
    "\n",
    "for input_size, depth in test_configs:\n",
    "    op = core.CreateOperator(\"LRN\")(\n",
    "        [\"X\"], [\"Y\", \"Y_scale\"], size=11, alpha=0.001, beta=0.5, bias=2.0, order=\"NHWC\")\n",
    "    X = np.random.rand(2, input_size, input_size, depth).astype(np.float32)\n",
    "    res = device_checker.CheckSimple(op, [X], [0])\n",
    "    print 'Device test for', input_size, depth, 'is: ', res\n",
    "    \n",
    "    res, grad, grad_estimated = cpu_g_checker.CheckSimple(op, [X], 0, [0])\n",
    "    print 'Test for cpu', input_size, depth, 'is: ', res\n",
    "    if not res:\n",
    "        pyplot.figure()\n",
    "        pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "    sys.stdout.flush()\n",
    "    res, grad, grad_estimated = gpu_g_checker.CheckSimple(op, [X], 0, [0])\n",
    "    print 'Test for gpu', input_size, depth, 'is: ', res\n",
    "    if not res:\n",
    "        pyplot.figure()\n",
    "        pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is for depth concat layers.\n",
    "test_configs = [\n",
    "(3, 2, 3, 4, 5),\n",
    "(4, 5, 4, 3, 2),   \n",
    "]\n",
    "\n",
    "for input_size, d1, d2, d3, d4 in test_configs:\n",
    "    op = core.CreateOperator(\"DepthConcat\")(\n",
    "        [\"X1\", \"X2\", \"X3\", \"X4\"], [\"Y\", \"Y_dims\"], order=\"NHWC\")\n",
    "    Xs = [np.random.rand(2, input_size, input_size, d1).astype(np.float32),\n",
    "          np.random.rand(2, input_size, input_size, d2).astype(np.float32),\n",
    "          np.random.rand(2, input_size, input_size, d3).astype(np.float32),\n",
    "          np.random.rand(2, input_size, input_size, d4).astype(np.float32)]\n",
    "    for i in range(4):\n",
    "        res = device_checker.CheckSimple(op, Xs, [0])\n",
    "        print 'Device test for', input_size, d1, d2, d3, d4, 'is: ', res\n",
    "        res, grad, grad_estimated = cpu_g_checker.CheckSimple(op, Xs, i, [0])\n",
    "        print 'Test for cpu', input_size, d1, d2, d3, d4, 'input id', i, 'is: ', res\n",
    "        if not res:\n",
    "            pyplot.figure()\n",
    "            pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "        sys.stdout.flush()\n",
    "        res, grad, grad_estimated = gpu_g_checker.CheckSimple(op, Xs, i, [0])\n",
    "        print 'Test for gpu', input_size, d1, d2, d3, d4, 'input id', i, 'is: ', res\n",
    "        if not res:\n",
    "            pyplot.figure()\n",
    "            pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is for Relu layers.\n",
    "checker = gradient_checker.GradientChecker(0.01, 0.05, \"default\")\n",
    "test_configs = [\n",
    "(1, 1),\n",
    "(2, 1),\n",
    "(1, 3, 3, 1),\n",
    "(2, 3, 3, 1),\n",
    "(1, 5, 5, 3),\n",
    "(2, 5, 5, 3),\n",
    "]\n",
    "\n",
    "for input_size in test_configs:\n",
    "    op = core.CreateOperator(\"Relu\")([\"X\"], [\"Y\"])\n",
    "    X = np.random.rand(*input_size).astype(np.float32)\n",
    "    # go away from the origin point to avoid kink problems\n",
    "    X += 0.01 * np.sign(X)\n",
    "    X[X==0] = 0.01\n",
    "    res = device_checker.CheckSimple(op, [X], [0])\n",
    "    print 'Device test for', input_size, 'is: ', res\n",
    "    res, grad, grad_estimated = cpu_g_checker.CheckSimple(op, [X], 0, [0])\n",
    "    print 'Test for cpu', input_size, 'is: ', res\n",
    "    if not res:\n",
    "        pyplot.figure()\n",
    "        pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "    sys.stdout.flush()\n",
    "    res, grad, grad_estimated = gpu_g_checker.CheckSimple(op, [X], 0, [0])\n",
    "    print 'Test for gpu', input_size, 'is: ', res\n",
    "    if not res:\n",
    "        pyplot.figure()\n",
    "        pyplot.plot(grad.flat, grad_estimated.flat)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
